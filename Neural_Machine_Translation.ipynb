{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVNiF_ngdBXM"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUXnhgzEtTLw"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UD-CF9Dduee"
   },
   "outputs": [],
   "source": [
    "# Load English data\n",
    "english_sentences = load_data('small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = load_data('small_vocab_fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMi-TH3ddxcS",
    "outputId": "baac697f-b164-4367-9ecb-0c3d440f0e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(1):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B11HtUJGeILZ",
    "outputId": "6fb9f5ae-c9b9-4c10-d8ac-0375dff9128f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 total English words.\n",
      "227 unique English words.\n",
      "\n",
      "1961295 total French words.\n",
      "355 unique French words.\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} total English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print()\n",
    "print('{} total French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMCawpsEeKim"
   },
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    tokenizer = Tokenizer(split=' ', char_level=False)\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    return tokenizer.texts_to_sequences(x), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR2JL4l0eMWJ"
   },
   "outputs": [],
   "source": [
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    \n",
    "    return pad_sequences(x, maxlen=length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0q8iLwfeNt7"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1) \n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5MQgkCzmW9A",
    "outputId": "e4593a6e-fa46-4806-9e1f-ede9d938e7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)\n",
    "\n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaBRCizBePq7",
    "outputId": "27d2708c-9a6e-46b5-c6d2-5023a40be96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137861, 15)\n"
     ]
    }
   ],
   "source": [
    "print(preproc_english_sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTszW0Brej5J"
   },
   "outputs": [],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {ids: word for word, ids in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    decoded_sentence = []\n",
    "    for prediction in np.argmax(logits, 1):\n",
    "      if index_to_words[prediction]!='<PAD>':\n",
    "        decoded_sentence.append(index_to_words[prediction])\n",
    "\n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5JBcbl2eo5t"
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_258FqXemoI"
   },
   "outputs": [],
   "source": [
    "def token_to_words(sequence, tokenizer):\n",
    "    index_to_words = {ids: word for word, ids in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    decoded_sentence = []\n",
    "    for token in sequence:\n",
    "      if index_to_words[token]!='<PAD>':\n",
    "        decoded_sentence.append(index_to_words[token])\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMuOjRDxsmBT"
   },
   "outputs": [],
   "source": [
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(64, return_sequences=True, activation=\"tanh\"))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation=\"softmax\")))\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.build((None,21,1)) # ????\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7zmAxJ8ofW4",
    "outputId": "74dd1346-12b6-4659-8bba-1c90cfd5cab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 21, 64)            16896     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 21, 344)          22360     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,256\n",
      "Trainable params: 39,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - 5s 19ms/step - loss: 3.3688 - accuracy: 0.4206 - val_loss: nan - val_accuracy: 0.4690\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 2.4047 - accuracy: 0.4771 - val_loss: nan - val_accuracy: 0.4882\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 2.1581 - accuracy: 0.5043 - val_loss: nan - val_accuracy: 0.5294\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.9411 - accuracy: 0.5509 - val_loss: nan - val_accuracy: 0.5670\n",
      "Epoch 5/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.7884 - accuracy: 0.5728 - val_loss: nan - val_accuracy: 0.5816\n",
      "Epoch 6/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.6966 - accuracy: 0.5837 - val_loss: nan - val_accuracy: 0.5907\n",
      "Epoch 7/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.6330 - accuracy: 0.5924 - val_loss: nan - val_accuracy: 0.5963\n",
      "Epoch 8/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.5810 - accuracy: 0.5980 - val_loss: nan - val_accuracy: 0.5998\n",
      "Epoch 9/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.5354 - accuracy: 0.6022 - val_loss: nan - val_accuracy: 0.6035\n",
      "Epoch 10/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.4951 - accuracy: 0.6091 - val_loss: nan - val_accuracy: 0.6104\n",
      "Epoch 11/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.4605 - accuracy: 0.6201 - val_loss: nan - val_accuracy: 0.6244\n",
      "Epoch 12/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.4290 - accuracy: 0.6264 - val_loss: nan - val_accuracy: 0.6278\n",
      "Epoch 13/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.4007 - accuracy: 0.6299 - val_loss: nan - val_accuracy: 0.6327\n",
      "Epoch 14/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.3736 - accuracy: 0.6344 - val_loss: nan - val_accuracy: 0.6357\n",
      "Epoch 15/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.3494 - accuracy: 0.6382 - val_loss: nan - val_accuracy: 0.6407\n",
      "Epoch 16/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.3278 - accuracy: 0.6412 - val_loss: nan - val_accuracy: 0.6434\n",
      "Epoch 17/20\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 1.3080 - accuracy: 0.6439 - val_loss: nan - val_accuracy: 0.6445\n",
      "Epoch 18/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.2909 - accuracy: 0.6451 - val_loss: nan - val_accuracy: 0.6463\n",
      "Epoch 19/20\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.2751 - accuracy: 0.6470 - val_loss: nan - val_accuracy: 0.6481\n",
      "Epoch 20/20\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 1.2612 - accuracy: 0.6485 - val_loss: nan - val_accuracy: 0.6498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d7cf65890>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "tmp_x = tmp_x.reshape(tmp_x.shape[0],tmp_x.shape[1],1) # reshape as 3D (batchsize, timesteps, 1) for LSTM input\n",
    "\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "\n",
    "simple_rnn_model.summary()\n",
    "\n",
    "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KM20mUAfvqZ"
   },
   "outputs": [],
   "source": [
    "def translate(prediction, french_sentence):\n",
    "    translation = logits_to_text(prediction[0], french_tokenizer)\n",
    "    standard = ' '.join(token_to_words(french_sentence[0][:,0],french_tokenizer)) \n",
    "    print('---- French Sentence ----')\n",
    "    print(standard)\n",
    "    print()\n",
    "    print('---- Prediction ----')\n",
    "    print(translation)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-AnuVQXf1ax",
    "outputId": "f34789b0-9d90-4eba-8c9f-d0a117ee1d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- English Sentence ----\n",
      "new jersey is sometimes quiet during autumn and it is snowy in april\n",
      "\n",
      "---- French Sentence ----\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
      "\n",
      "---- Prediction ----\n",
      "new jersey est parfois chaud en l' et il est est en en\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---- English Sentence ----')\n",
    "print(' '.join(token_to_words(tmp_x[:1][0][:,0],english_tokenizer)))\n",
    "print()\n",
    "translate(simple_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT9MZyIF2d8r"
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXb6AFrvvIEH"
   },
   "outputs": [],
   "source": [
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    learning_rate = 0.001\n",
    "    embedding_size = 256 # dimensions of word vectors\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
    "                           input_length = output_sequence_length))\n",
    "    \n",
    "    model.add(LSTM(64, return_sequences=True, activation=\"tanh\"))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation=\"softmax\")))\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uESS2Ibz20O3",
    "outputId": "786437ad-fba5-4a5b-ef61-e7cf90c4c157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 21, 256)           50944     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 21, 64)            82176     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 21, 344)          22360     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,480\n",
      "Trainable params: 155,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - 4s 21ms/step - loss: 3.5627 - accuracy: 0.4053 - val_loss: nan - val_accuracy: 0.4425\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 2.4110 - accuracy: 0.4902 - val_loss: nan - val_accuracy: 0.5354\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 1.7719 - accuracy: 0.5832 - val_loss: nan - val_accuracy: 0.6267\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 1.3571 - accuracy: 0.6644 - val_loss: nan - val_accuracy: 0.7050\n",
      "Epoch 5/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 1.0457 - accuracy: 0.7346 - val_loss: nan - val_accuracy: 0.7615\n",
      "Epoch 6/20\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.8535 - accuracy: 0.7748 - val_loss: nan - val_accuracy: 0.7879\n",
      "Epoch 7/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.7427 - accuracy: 0.7952 - val_loss: nan - val_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.6699 - accuracy: 0.8095 - val_loss: nan - val_accuracy: 0.8167\n",
      "Epoch 9/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.6159 - accuracy: 0.8217 - val_loss: nan - val_accuracy: 0.8293\n",
      "Epoch 10/20\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.5717 - accuracy: 0.8334 - val_loss: nan - val_accuracy: 0.8389\n",
      "Epoch 11/20\n",
      "108/108 [==============================] - 2s 18ms/step - loss: 0.5333 - accuracy: 0.8437 - val_loss: nan - val_accuracy: 0.8487\n",
      "Epoch 12/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.5018 - accuracy: 0.8523 - val_loss: nan - val_accuracy: 0.8554\n",
      "Epoch 13/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4745 - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4510 - accuracy: 0.8664 - val_loss: nan - val_accuracy: 0.8697\n",
      "Epoch 15/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4313 - accuracy: 0.8718 - val_loss: nan - val_accuracy: 0.8736\n",
      "Epoch 16/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.4145 - accuracy: 0.8763 - val_loss: nan - val_accuracy: 0.8796\n",
      "Epoch 17/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3974 - accuracy: 0.8818 - val_loss: nan - val_accuracy: 0.8835\n",
      "Epoch 18/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3847 - accuracy: 0.8853 - val_loss: nan - val_accuracy: 0.8868\n",
      "Epoch 19/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3720 - accuracy: 0.8888 - val_loss: nan - val_accuracy: 0.8884\n",
      "Epoch 20/20\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 0.3627 - accuracy: 0.8910 - val_loss: nan - val_accuracy: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d78adc550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "# tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshaped to (batchsize, seq_length) for Embedding input\n",
    "\n",
    "# Train the neural network\n",
    "embed_rnn_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    max_french_sequence_length,\n",
    "    english_vocab_size,\n",
    "    french_vocab_size)\n",
    "\n",
    "embed_rnn_model.summary()\n",
    "    \n",
    "embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhH3-7bP22Ds",
    "outputId": "bb04edba-de84-47e3-d3a1-193e0b8b0376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- English Sentence ----\n",
      "new jersey is sometimes quiet during autumn and it is snowy in april\n",
      "\n",
      "---- French Sentence ----\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
      "\n",
      "---- Prediction ----\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---- English Sentence ----')\n",
    "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
    "print()\n",
    "translate(embed_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxROZJxx7MfN"
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGXaKJ_u5Tbg"
   },
   "outputs": [],
   "source": [
    "def emb_bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    learning_rate = 0.001\n",
    "    embedding_size = 256\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
    "                           input_length = output_sequence_length))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True, activation=\"tanh\")))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation=\"softmax\")))\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WxMqabd7OXO",
    "outputId": "196b0724-9f35-4f58-b163-affa0bfb98c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 21, 256)           50944     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 21, 128)          164352    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 21, 344)          44376     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259,672\n",
      "Trainable params: 259,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - 6s 31ms/step - loss: 3.1397 - accuracy: 0.4511 - val_loss: nan - val_accuracy: 0.5014\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 1.9493 - accuracy: 0.5434 - val_loss: nan - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 1.3385 - accuracy: 0.6592 - val_loss: nan - val_accuracy: 0.7174\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.9399 - accuracy: 0.7480 - val_loss: nan - val_accuracy: 0.7745\n",
      "Epoch 5/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.7360 - accuracy: 0.7912 - val_loss: nan - val_accuracy: 0.8071\n",
      "Epoch 6/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.6201 - accuracy: 0.8182 - val_loss: nan - val_accuracy: 0.8270\n",
      "Epoch 7/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.5404 - accuracy: 0.8397 - val_loss: nan - val_accuracy: 0.8503\n",
      "Epoch 8/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.4823 - accuracy: 0.8570 - val_loss: nan - val_accuracy: 0.8652\n",
      "Epoch 9/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.4381 - accuracy: 0.8697 - val_loss: nan - val_accuracy: 0.8740\n",
      "Epoch 10/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.4031 - accuracy: 0.8800 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 11/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.3736 - accuracy: 0.8887 - val_loss: nan - val_accuracy: 0.8933\n",
      "Epoch 12/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.3498 - accuracy: 0.8960 - val_loss: nan - val_accuracy: 0.9003\n",
      "Epoch 13/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.3272 - accuracy: 0.9029 - val_loss: nan - val_accuracy: 0.9061\n",
      "Epoch 14/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.3093 - accuracy: 0.9081 - val_loss: nan - val_accuracy: 0.9044\n",
      "Epoch 15/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2930 - accuracy: 0.9132 - val_loss: nan - val_accuracy: 0.9144\n",
      "Epoch 16/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2777 - accuracy: 0.9181 - val_loss: nan - val_accuracy: 0.9193\n",
      "Epoch 17/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2670 - accuracy: 0.9209 - val_loss: nan - val_accuracy: 0.9223\n",
      "Epoch 18/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2528 - accuracy: 0.9255 - val_loss: nan - val_accuracy: 0.9268\n",
      "Epoch 19/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2426 - accuracy: 0.9286 - val_loss: nan - val_accuracy: 0.9289\n",
      "Epoch 20/20\n",
      "108/108 [==============================] - 3s 24ms/step - loss: 0.2331 - accuracy: 0.9314 - val_loss: nan - val_accuracy: 0.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d788b91d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length)\n",
    "\n",
    "# Train the neural network\n",
    "emb_bd_rnn_model = emb_bd_model(\n",
    "                        tmp_x.shape,\n",
    "                        max_french_sequence_length,\n",
    "                        english_vocab_size,\n",
    "                        french_vocab_size)\n",
    "\n",
    "emb_bd_rnn_model.summary()\n",
    "\n",
    "emb_bd_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RStclaED7Wb9",
    "outputId": "2e9d9fa2-0644-4404-b399-663720956410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- English Sentence ----\n",
      "new jersey is sometimes quiet during autumn and it is snowy in april\n",
      "\n",
      "---- French Sentence ----\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
      "\n",
      "---- Prediction ----\n",
      "new jersey est parfois calme en automne et il est neigeux en avril\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---- English Sentence ----')\n",
    "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
    "print()\n",
    "translate(emb_bd_rnn_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RamWhc-M8ul4"
   },
   "source": [
    "## Model 4\n",
    "Read this https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p-ACVYd75qu"
   },
   "outputs": [],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    learning_rate = 6e-3\n",
    "    embedding_size = 256\n",
    "    units = 256\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    ########### ENCODER ###########\n",
    "    \n",
    "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
    "                           input_length= input_shape[1], name=\"Embedding_layer\"))\n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=False), name='Bi_LSTM_Encoder'))\n",
    "    \n",
    "    ########### INTERMEDIARY ###########\n",
    "    # Repeat Vector adjusts the shape of the Encoder output (2D) to the need of the Decoder (3D input).\n",
    "    # We repeat the 2D vector over sequence_length times to produce the shape (batchsize, seq_length, num_units)\n",
    "    model.add(RepeatVector(output_sequence_length, name='RepeatVector'))\n",
    "    \n",
    "    ########### DECODER ###########\n",
    "    \n",
    "    model.add(LSTM(units, return_sequences=True, name='LSTM_Decoder'))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'), name='Dense'))\n",
    "\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dhjs9pvB0Gy",
    "outputId": "5b3729bb-dccc-481d-8d1a-30fdb181c599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Embedding_layer (Embedding)  (None, 21, 256)          50944     \n",
      "                                                                 \n",
      " Bi_LSTM_Encoder (Bidirectio  (None, 512)              1050624   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " RepeatVector (RepeatVector)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " LSTM_Decoder (LSTM)         (None, 21, 256)           787456    \n",
      "                                                                 \n",
      " Dense (TimeDistributed)     (None, 21, 344)           88408     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977,432\n",
      "Trainable params: 1,977,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "108/108 [==============================] - 15s 107ms/step - loss: 2.4671 - accuracy: 0.4782 - val_loss: nan - val_accuracy: 0.5608\n",
      "Epoch 2/20\n",
      "108/108 [==============================] - 11s 98ms/step - loss: 1.5372 - accuracy: 0.5993 - val_loss: nan - val_accuracy: 0.6471\n",
      "Epoch 3/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 1.1799 - accuracy: 0.6784 - val_loss: nan - val_accuracy: 0.6800\n",
      "Epoch 4/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.9853 - accuracy: 0.7274 - val_loss: nan - val_accuracy: 0.7486\n",
      "Epoch 5/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.8105 - accuracy: 0.7706 - val_loss: nan - val_accuracy: 0.7962\n",
      "Epoch 6/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.6536 - accuracy: 0.8138 - val_loss: nan - val_accuracy: 0.8370\n",
      "Epoch 7/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.5206 - accuracy: 0.8494 - val_loss: nan - val_accuracy: 0.8686\n",
      "Epoch 8/20\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.4086 - accuracy: 0.8831 - val_loss: nan - val_accuracy: 0.8939\n",
      "Epoch 9/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.3535 - accuracy: 0.8992 - val_loss: nan - val_accuracy: 0.9144\n",
      "Epoch 10/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.2614 - accuracy: 0.9292 - val_loss: nan - val_accuracy: 0.9343\n",
      "Epoch 11/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.2135 - accuracy: 0.9448 - val_loss: nan - val_accuracy: 0.9485\n",
      "Epoch 12/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.1757 - accuracy: 0.9558 - val_loss: nan - val_accuracy: 0.9443\n",
      "Epoch 13/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.1534 - accuracy: 0.9615 - val_loss: nan - val_accuracy: 0.9616\n",
      "Epoch 14/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.1250 - accuracy: 0.9698 - val_loss: nan - val_accuracy: 0.9629\n",
      "Epoch 15/20\n",
      "108/108 [==============================] - 11s 101ms/step - loss: 0.1067 - accuracy: 0.9744 - val_loss: nan - val_accuracy: 0.9713\n",
      "Epoch 16/20\n",
      "108/108 [==============================] - 11s 101ms/step - loss: 0.0952 - accuracy: 0.9772 - val_loss: nan - val_accuracy: 0.9721\n",
      "Epoch 17/20\n",
      "108/108 [==============================] - 11s 101ms/step - loss: 0.0878 - accuracy: 0.9784 - val_loss: nan - val_accuracy: 0.9745\n",
      "Epoch 18/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.0759 - accuracy: 0.9816 - val_loss: nan - val_accuracy: 0.9774\n",
      "Epoch 19/20\n",
      "108/108 [==============================] - 11s 101ms/step - loss: 0.0724 - accuracy: 0.9821 - val_loss: nan - val_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.0818 - accuracy: 0.9783 - val_loss: nan - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d775a0250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = pad(preproc_english_sentences, max_french_sequence_length) # pad input sequence to output sequence length\n",
    "\n",
    "# Train the neural network\n",
    "final_model = model_final(\n",
    "                        tmp_x.shape,\n",
    "                        max_french_sequence_length,\n",
    "                        english_vocab_size,\n",
    "                        french_vocab_size)\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "final_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFN5vWCRB1fA",
    "outputId": "05454b9f-8093-431b-8bfc-163b15ffa009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- English Sentence ----\n",
      "new jersey is sometimes quiet during autumn and it is snowy in april\n",
      "\n",
      "---- French Sentence ----\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril\n",
      "\n",
      "---- Prediction ----\n",
      "new jersey est parfois calme à l'automne et il est neigeux en avril\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---- English Sentence ----')\n",
    "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n",
    "print()\n",
    "translate(final_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Machine Translation.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
